{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%pip install transformers torch pandas matplotlib sentence-transformers"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "19ee05eb1dccee72"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-25T17:13:39.773251Z",
     "start_time": "2024-10-25T17:13:36.727714Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aceto/anaconda3/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prepare the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b70a7525b4a1612"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "SOURCE = \"data/games.csv\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-25T17:13:48.103905Z",
     "start_time": "2024-10-25T17:13:48.098769Z"
    }
   },
   "id": "78d90fa3cf63df53"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def process_games_data(source):\n",
    "    # Read the CSV file\n",
    "    games = pd.read_csv(source)\n",
    "\n",
    "    # Select relevant columns\n",
    "    games = games[['AppID', 'Name', 'About the game', 'Supported languages', 'Genres']]\n",
    "\n",
    "    # Rename columns\n",
    "    games.columns = ['id', 'name', 'description', 'languages', 'genres']\n",
    "\n",
    "    # Drop rows with missing descriptions\n",
    "    games = games.dropna(subset=['description'])\n",
    "\n",
    "    # Filter games with English available\n",
    "    games['english_available'] = games['languages'].apply(lambda x: 'english' in x.lower())\n",
    "    games = games[games['english_available']]\n",
    "\n",
    "    # Filter games with description length greater than 120\n",
    "    games = games[games['description'].apply(lambda x: len(str(x))) > 120]\n",
    "\n",
    "    # Truncate descriptions to 3000 characters\n",
    "    games['description'] = games['description'].apply(lambda x: x[:3000])\n",
    "    \n",
    "    #Remove not needed columns\n",
    "    games = games.drop(columns=['languages', 'english_available'])\n",
    "\n",
    "    return games"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-25T17:23:54.197531Z",
     "start_time": "2024-10-25T17:23:54.190688Z"
    }
   },
   "id": "4fb4a4cb7e1d467"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aceto/anaconda3/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\"all-mpnet-base-v2\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-25T17:23:56.682392Z",
     "start_time": "2024-10-25T17:23:54.674243Z"
    }
   },
   "id": "3b55eed2daa46122"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Experiment 1: Similarity only based on description"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e9d1e8824a6382cd"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "count                                                 87945\nunique                                                87463\ntop       Help the beautiful girls to immerse themselves...\nfreq                                                     65\nName: description, dtype: object"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games_1 = process_games_data(SOURCE)\n",
    "games_1['description'].describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-25T17:23:59.280643Z",
     "start_time": "2024-10-25T17:23:56.657990Z"
    }
   },
   "id": "e9b0d6ff920fe24c"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "            id                    name  \\\n0        20200        Galactic Bowling   \n1       655370            Train Bandit   \n2      1732930            Jolt Project   \n3      1355720                Henosis™   \n4      1139950   Two Weeks in Painland   \n...        ...                     ...   \n97405  3080940  Femdom Game World: Mom   \n97406  2593970             Blocky Farm   \n97407  3137150    Infiltrate & Extract   \n97408  3124670       Escape The Garage   \n97409  3054200              Lober Lobe   \n\n                                             description  \\\n0      Galactic Bowling is an exaggerated and stylize...   \n1      THE LAW!! Looks to be a showdown atop a train....   \n2      Jolt Project: The army now has a new robotics ...   \n3      HENOSIS™ is a mysterious 2D Platform Puzzler w...   \n4      ABOUT THE GAME Play as a hacker who has arrang...   \n...                                                  ...   \n97405  . Femdom Game World - is a fascinating series ...   \n97406  Enter the charming world of Blocky Farm where ...   \n97407  Mission brief: You are deployed to a heavily g...   \n97408  Welcome to Escape The Garage, the thrilling es...   \n97409  Scan Brain Lobes Organize &amp; clear dangerou...   \n\n                                genres  \n0                  Casual,Indie,Sports  \n1                         Action,Indie  \n2      Action,Adventure,Indie,Strategy  \n3               Adventure,Casual,Indie  \n4                      Adventure,Indie  \n...                                ...  \n97405                           Casual  \n97406       Casual,Simulation,Strategy  \n97407            Strategy,Free To Play  \n97408           Adventure,Casual,Indie  \n97409              Action,Casual,Indie  \n\n[87945 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n      <th>description</th>\n      <th>genres</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20200</td>\n      <td>Galactic Bowling</td>\n      <td>Galactic Bowling is an exaggerated and stylize...</td>\n      <td>Casual,Indie,Sports</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>655370</td>\n      <td>Train Bandit</td>\n      <td>THE LAW!! Looks to be a showdown atop a train....</td>\n      <td>Action,Indie</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1732930</td>\n      <td>Jolt Project</td>\n      <td>Jolt Project: The army now has a new robotics ...</td>\n      <td>Action,Adventure,Indie,Strategy</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1355720</td>\n      <td>Henosis™</td>\n      <td>HENOSIS™ is a mysterious 2D Platform Puzzler w...</td>\n      <td>Adventure,Casual,Indie</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1139950</td>\n      <td>Two Weeks in Painland</td>\n      <td>ABOUT THE GAME Play as a hacker who has arrang...</td>\n      <td>Adventure,Indie</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>97405</th>\n      <td>3080940</td>\n      <td>Femdom Game World: Mom</td>\n      <td>. Femdom Game World - is a fascinating series ...</td>\n      <td>Casual</td>\n    </tr>\n    <tr>\n      <th>97406</th>\n      <td>2593970</td>\n      <td>Blocky Farm</td>\n      <td>Enter the charming world of Blocky Farm where ...</td>\n      <td>Casual,Simulation,Strategy</td>\n    </tr>\n    <tr>\n      <th>97407</th>\n      <td>3137150</td>\n      <td>Infiltrate &amp; Extract</td>\n      <td>Mission brief: You are deployed to a heavily g...</td>\n      <td>Strategy,Free To Play</td>\n    </tr>\n    <tr>\n      <th>97408</th>\n      <td>3124670</td>\n      <td>Escape The Garage</td>\n      <td>Welcome to Escape The Garage, the thrilling es...</td>\n      <td>Adventure,Casual,Indie</td>\n    </tr>\n    <tr>\n      <th>97409</th>\n      <td>3054200</td>\n      <td>Lober Lobe</td>\n      <td>Scan Brain Lobes Organize &amp;amp; clear dangerou...</td>\n      <td>Action,Casual,Indie</td>\n    </tr>\n  </tbody>\n</table>\n<p>87945 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games_1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-25T17:23:59.281558Z",
     "start_time": "2024-10-25T17:23:59.271914Z"
    }
   },
   "id": "8a65e0c786034ab1"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m games_1[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124membeddings\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mencode(games_1[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdescription\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mtolist())\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:650\u001B[0m, in \u001B[0;36mSentenceTransformer.encode\u001B[0;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, **kwargs)\u001B[0m\n\u001B[1;32m    648\u001B[0m             \u001B[38;5;66;03m# fixes for #522 and #487 to avoid oom problems on gpu with large datasets\u001B[39;00m\n\u001B[1;32m    649\u001B[0m             \u001B[38;5;28;01mif\u001B[39;00m convert_to_numpy:\n\u001B[0;32m--> 650\u001B[0m                 embeddings \u001B[38;5;241m=\u001B[39m embeddings\u001B[38;5;241m.\u001B[39mcpu()\n\u001B[1;32m    652\u001B[0m         all_embeddings\u001B[38;5;241m.\u001B[39mextend(embeddings)\n\u001B[1;32m    654\u001B[0m all_embeddings \u001B[38;5;241m=\u001B[39m [all_embeddings[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m np\u001B[38;5;241m.\u001B[39margsort(length_sorted_idx)]\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "#games_1['embeddings'] = model.encode(games_1['description'].tolist())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-25T17:30:31.488507Z",
     "start_time": "2024-10-25T17:28:08.257095Z"
    }
   },
   "id": "a33aa86ab069159e"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3r/gx5x0f7n6lvd5yzgw2zddpv80000gn/T/ipykernel_28526/3141478878.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  g_1['embeddings'] = [model.encode(g_1['description'].iloc[0]).tolist()]\n",
      "/var/folders/3r/gx5x0f7n6lvd5yzgw2zddpv80000gn/T/ipykernel_28526/3141478878.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  g_2['embeddings'] = [model.encode(g_2['description'].iloc[0]).tolist()]\n",
      "/var/folders/3r/gx5x0f7n6lvd5yzgw2zddpv80000gn/T/ipykernel_28526/3141478878.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  g_3['embeddings'] = [model.encode(g_3['description'].iloc[0]).tolist()]\n"
     ]
    }
   ],
   "source": [
    "#get to similar games\n",
    "g_1 = games_1[games_1[\"id\"] == 849177]\n",
    "g_2 = games_1[games_1[\"id\"] == 391220]\n",
    "#Get one not similar\n",
    "g_3 = games_1[games_1[\"id\"] == 1659180]\n",
    "#Get embeddings\n",
    "g_1['embeddings'] = [model.encode(g_1['description'].iloc[0]).tolist()]\n",
    "g_2['embeddings'] = [model.encode(g_2['description'].iloc[0]).tolist()]\n",
    "g_3['embeddings'] = [model.encode(g_3['description'].iloc[0]).tolist()]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-25T17:36:14.148014Z",
     "start_time": "2024-10-25T17:36:13.965840Z"
    }
   },
   "id": "966730f8d9c469a2"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "13400    [0.001636300585232675, 0.061147015541791916, -...\nName: embeddings, dtype: object"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_2['embeddings']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-25T17:36:26.958592Z",
     "start_time": "2024-10-25T17:36:26.950424Z"
    }
   },
   "id": "84846d119d3bda"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between Shadow of the Tomb Raider: Definitive Edition and Rise of the Tomb Raider™: 0.8550347089767456 -> should be high\n",
      "Similarity between Shadow of the Tomb Raider: Definitive Edition and TD Worlds: 0.3918170928955078 -> should be low\n"
     ]
    }
   ],
   "source": [
    "sim_1_2 = model.similarity(g_1['embeddings'].values[0], g_2['embeddings'].values[0])\n",
    "sim_1_3 = model.similarity(g_1['embeddings'].values[0], g_3['embeddings'].values[0])\n",
    "print(f\"Similarity between {g_1['name'].values[0]} and {g_2['name'].values[0]}: {sim_1_2[0][0]} -> should be high\")\n",
    "print(f\"Similarity between {g_1['name'].values[0]} and {g_3['name'].values[0]}: {sim_1_3[0][0]} -> should be low\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-25T17:37:36.000638Z",
     "start_time": "2024-10-25T17:37:35.992678Z"
    }
   },
   "id": "7f14a5ba7a2d17fb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Experiment 2: Similarity based on description and genres (weighted approach)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "52e78f80586c6acc"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "games_2 = process_games_data(SOURCE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-25T17:42:34.656050Z",
     "start_time": "2024-10-25T17:42:31.963936Z"
    }
   },
   "id": "91005ff7286d4bc2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Description embedding same as before"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2111f327d2146a87"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3r/gx5x0f7n6lvd5yzgw2zddpv80000gn/T/ipykernel_28526/1140898956.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  g_1['desc_embeddings'] = [model.encode(g_1['description'].iloc[0]).tolist()]\n",
      "/var/folders/3r/gx5x0f7n6lvd5yzgw2zddpv80000gn/T/ipykernel_28526/1140898956.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  g_2['desc_embeddings'] = [model.encode(g_2['description'].iloc[0]).tolist()]\n",
      "/var/folders/3r/gx5x0f7n6lvd5yzgw2zddpv80000gn/T/ipykernel_28526/1140898956.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  g_3['desc_embeddings'] = [model.encode(g_3['description'].iloc[0]).tolist()]\n"
     ]
    }
   ],
   "source": [
    "g_1 = games_2[games_2[\"id\"] == 849177]\n",
    "g_2 = games_2[games_2[\"id\"] == 391220]\n",
    "#Get one not similar\n",
    "g_3 = games_2[games_2[\"id\"] == 1659180]\n",
    "#Get embeddings\n",
    "g_1['desc_embeddings'] = [model.encode(g_1['description'].iloc[0]).tolist()]\n",
    "g_2['desc_embeddings'] = [model.encode(g_2['description'].iloc[0]).tolist()]\n",
    "g_3['desc_embeddings'] = [model.encode(g_3['description'].iloc[0]).tolist()]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-25T17:42:35.136562Z",
     "start_time": "2024-10-25T17:42:34.657204Z"
    }
   },
   "id": "a5dae0f1e1d5c5df"
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "7776    [0.01750553771853447, 0.05562837794423103, -0....\nName: desc_embeddings, dtype: object"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_1['desc_embeddings']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-25T17:57:05.388598Z",
     "start_time": "2024-10-25T17:57:05.375903Z"
    }
   },
   "id": "6fc1b1bcb9ecbd9e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Genres embedding\n",
    "- Option one would be one hot encoding and just see how many genres are in common\n",
    "- Option two would be to use bert (single word) and then average the embeddings, get similarity"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7327793e510e3417"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3r/gx5x0f7n6lvd5yzgw2zddpv80000gn/T/ipykernel_28526/1949706108.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  g_1['genres'] = g_1['genres'].apply(lambda x: x.split(', '))\n",
      "/var/folders/3r/gx5x0f7n6lvd5yzgw2zddpv80000gn/T/ipykernel_28526/1949706108.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  g_2['genres'] = g_2['genres'].apply(lambda x: x.split(', '))\n",
      "/var/folders/3r/gx5x0f7n6lvd5yzgw2zddpv80000gn/T/ipykernel_28526/1949706108.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  g_3['genres'] = g_3['genres'].apply(lambda x: x.split(', '))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[44], line 6\u001B[0m\n\u001B[1;32m      4\u001B[0m g_2[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgenres\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m g_2[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgenres\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x: x\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[1;32m      5\u001B[0m g_3[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgenres\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m g_3[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgenres\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x: x\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[0;32m----> 6\u001B[0m genres \u001B[38;5;241m=\u001B[39m mlb\u001B[38;5;241m.\u001B[39mfit_transform(games_2[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgenres\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m      7\u001B[0m genres \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(genres, columns\u001B[38;5;241m=\u001B[39mmlb\u001B[38;5;241m.\u001B[39mclasses_)\n\u001B[1;32m      8\u001B[0m genres\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1473\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1466\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m   1468\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m   1469\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m   1470\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m   1471\u001B[0m     )\n\u001B[1;32m   1472\u001B[0m ):\n\u001B[0;32m-> 1473\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_label.py:819\u001B[0m, in \u001B[0;36mMultiLabelBinarizer.fit_transform\u001B[0;34m(self, y)\u001B[0m\n\u001B[1;32m    817\u001B[0m class_mapping \u001B[38;5;241m=\u001B[39m defaultdict(\u001B[38;5;28mint\u001B[39m)\n\u001B[1;32m    818\u001B[0m class_mapping\u001B[38;5;241m.\u001B[39mdefault_factory \u001B[38;5;241m=\u001B[39m class_mapping\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__len__\u001B[39m\n\u001B[0;32m--> 819\u001B[0m yt \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_transform(y, class_mapping)\n\u001B[1;32m    821\u001B[0m \u001B[38;5;66;03m# sort classes and reorder columns\u001B[39;00m\n\u001B[1;32m    822\u001B[0m tmp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msorted\u001B[39m(class_mapping, key\u001B[38;5;241m=\u001B[39mclass_mapping\u001B[38;5;241m.\u001B[39mget)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_label.py:892\u001B[0m, in \u001B[0;36mMultiLabelBinarizer._transform\u001B[0;34m(self, y, class_mapping)\u001B[0m\n\u001B[1;32m    890\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m labels \u001B[38;5;129;01min\u001B[39;00m y:\n\u001B[1;32m    891\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n\u001B[0;32m--> 892\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m label \u001B[38;5;129;01min\u001B[39;00m labels:\n\u001B[1;32m    893\u001B[0m         \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    894\u001B[0m             index\u001B[38;5;241m.\u001B[39madd(class_mapping[label])\n",
      "\u001B[0;31mTypeError\u001B[0m: 'float' object is not iterable"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "g_1['genres'] = g_1['genres'].apply(lambda x: x.split(', '))\n",
    "g_2['genres'] = g_2['genres'].apply(lambda x: x.split(', '))\n",
    "g_3['genres'] = g_3['genres'].apply(lambda x: x.split(', '))\n",
    "#genres = mlb.fit_transform(games_2['genres'])\n",
    "#genres = pd.DataFrame(genres, columns=mlb.classes_)\n",
    "#genres"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-25T17:45:50.975806Z",
     "start_time": "2024-10-25T17:45:50.898906Z"
    }
   },
   "id": "fb1e405dc97799d3"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aceto/anaconda3/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-25T17:46:47.629592Z",
     "start_time": "2024-10-25T17:46:47.108307Z"
    }
   },
   "id": "5a23cf79a87e6e7e"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "def get_genre_embeddings(genres: list):\n",
    "    genre_embeddings = []\n",
    "    for genre in genres:\n",
    "        inputs = tokenizer(genre, return_tensors=\"pt\")\n",
    "        outputs = model(**inputs)\n",
    "        genre_embeddings.append(outputs.last_hidden_state.mean(dim=1).detach().numpy())\n",
    "    return np.mean(genre_embeddings, axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-25T17:46:48.734547Z",
     "start_time": "2024-10-25T17:46:48.731672Z"
    }
   },
   "id": "5a10d363f472c458"
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3r/gx5x0f7n6lvd5yzgw2zddpv80000gn/T/ipykernel_28526/287222231.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  g_1['genre_embeddings'] = [get_genre_embeddings(g_1['genres'].iloc[0])]\n",
      "/var/folders/3r/gx5x0f7n6lvd5yzgw2zddpv80000gn/T/ipykernel_28526/287222231.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  g_2['genre_embeddings'] = [get_genre_embeddings(g_2['genres'].iloc[0])]\n",
      "/var/folders/3r/gx5x0f7n6lvd5yzgw2zddpv80000gn/T/ipykernel_28526/287222231.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  g_3['genre_embeddings'] = [get_genre_embeddings(g_3['genres'].iloc[0])]\n",
      "/var/folders/3r/gx5x0f7n6lvd5yzgw2zddpv80000gn/T/ipykernel_28526/287222231.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  g_1['genre_embeddings'] = g_1['genre_embeddings'].apply(lambda x: x.tolist()[0])\n",
      "/var/folders/3r/gx5x0f7n6lvd5yzgw2zddpv80000gn/T/ipykernel_28526/287222231.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  g_2['genre_embeddings'] = g_2['genre_embeddings'].apply(lambda x: x.tolist()[0])\n",
      "/var/folders/3r/gx5x0f7n6lvd5yzgw2zddpv80000gn/T/ipykernel_28526/287222231.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  g_3['genre_embeddings'] = g_3['genre_embeddings'].apply(lambda x: x.tolist()[0])\n"
     ]
    }
   ],
   "source": [
    "g_1['genre_embeddings'] = [get_genre_embeddings(g_1['genres'].iloc[0])]\n",
    "g_2['genre_embeddings'] = [get_genre_embeddings(g_2['genres'].iloc[0])]\n",
    "g_3['genre_embeddings'] = [get_genre_embeddings(g_3['genres'].iloc[0])]\n",
    "#Flatten the saved lists\n",
    "g_1['genre_embeddings'] = g_1['genre_embeddings'].apply(lambda x: x.tolist()[0])\n",
    "g_2['genre_embeddings'] = g_2['genre_embeddings'].apply(lambda x: x.tolist()[0])\n",
    "g_3['genre_embeddings'] = g_3['genre_embeddings'].apply(lambda x: x.tolist()[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-25T17:56:41.849719Z",
     "start_time": "2024-10-25T17:56:41.681934Z"
    }
   },
   "id": "f3a3cb7e6f04a8cb"
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "[-0.10142902284860611,\n -0.061262160539627075,\n 0.09484749287366867,\n 0.17833411693572998,\n 0.3531375527381897,\n -0.5199637413024902,\n 0.39155155420303345,\n 0.20382559299468994,\n -0.2825397551059723,\n 0.08408655971288681,\n -0.43010348081588745,\n 0.22484596073627472,\n 0.07554317265748978,\n 0.5022488832473755,\n 0.23771071434020996,\n 0.2497600018978119,\n 0.00610765814781189,\n 0.0700867623090744,\n 0.17763184010982513,\n 0.1675715297460556,\n 0.027022946625947952,\n -0.18263892829418182,\n 0.0390826091170311,\n 0.025111520662903786,\n 0.4033457338809967,\n 0.03307180106639862,\n -0.17355890572071075,\n -0.279629647731781,\n -0.28095346689224243,\n -0.13600359857082367,\n -0.1508440226316452,\n -0.15485021471977234,\n -0.32705071568489075,\n 0.17028075456619263,\n 0.07001380622386932,\n -0.23269128799438477,\n -0.22197452187538147,\n 0.16080662608146667,\n -0.11361221969127655,\n 0.029191672801971436,\n 0.042666833847761154,\n -0.17990057170391083,\n 0.31374722719192505,\n -0.1623702347278595,\n 0.31818538904190063,\n -0.34348782896995544,\n -0.44730836153030396,\n 0.13991954922676086,\n -0.5049487948417664,\n -0.1546405851840973,\n -0.18531018495559692,\n 0.19290278851985931,\n 0.10758209228515625,\n -0.003170082811266184,\n 0.19215910136699677,\n 0.7224690914154053,\n -0.13901230692863464,\n -0.043655894696712494,\n 0.024930929765105247,\n 0.22550606727600098,\n -0.07148806750774384,\n 0.29516202211380005,\n 0.13517382740974426,\n -0.2413649559020996,\n 0.023506557568907738,\n -0.006320786662399769,\n -0.0758085548877716,\n -0.014203009195625782,\n -0.010737299919128418,\n 0.004315680358558893,\n -0.012648379430174828,\n -0.3451233506202698,\n 0.27474260330200195,\n 0.2515774965286255,\n 0.015239933505654335,\n -0.1325339674949646,\n 0.10843588411808014,\n 0.20837053656578064,\n -0.01183332223445177,\n -0.1675405204296112,\n 0.22284922003746033,\n 0.26909226179122925,\n 0.506067156791687,\n 0.19873592257499695,\n 0.18342778086662292,\n 0.08564241230487823,\n -0.17417752742767334,\n -0.14491093158721924,\n -0.08197811990976334,\n 0.18586117029190063,\n 0.12380582094192505,\n -0.1690864861011505,\n -0.20304623246192932,\n 0.34840160608291626,\n 0.31443706154823303,\n 0.044146884232759476,\n -0.30292075872421265,\n 0.1201840415596962,\n -0.11222536861896515,\n -0.1426372528076172,\n 0.025095980614423752,\n -0.16399884223937988,\n 0.2244313657283783,\n 0.05893899127840996,\n 0.06173223257064819,\n 0.1838523894548416,\n 0.0480530709028244,\n -0.12517862021923065,\n -0.023163195699453354,\n -0.6870107650756836,\n 0.09639545530080795,\n -0.040662746876478195,\n 0.17222143709659576,\n -0.24352595210075378,\n -0.05972326919436455,\n 0.3375299572944641,\n 0.2863749861717224,\n 0.18071874976158142,\n -0.27260035276412964,\n 0.16148865222930908,\n -0.09030648320913315,\n -0.25361886620521545,\n -0.13138829171657562,\n 0.8002783060073853,\n 0.3951351046562195,\n 0.3662259578704834,\n -0.11713708937168121,\n -0.2416767179965973,\n 0.020559098571538925,\n -0.2788518965244293,\n -0.15913493931293488,\n 0.43166667222976685,\n -0.18781757354736328,\n -0.10893149673938751,\n -0.311471164226532,\n 0.2775103747844696,\n 0.22469481825828552,\n -0.15381327271461487,\n -0.08138037472963333,\n -0.3690088391304016,\n -0.11791770160198212,\n -0.06730097532272339,\n -0.672805905342102,\n -0.1872120350599289,\n 0.3507627546787262,\n 0.11956912279129028,\n 0.11847376823425293,\n 0.2086309939622879,\n 0.027177786454558372,\n 0.026853298768401146,\n 0.09881459921598434,\n -0.16757483780384064,\n -0.25203269720077515,\n -0.3814430832862854,\n -0.3082755208015442,\n 0.08953060954809189,\n -0.28568926453590393,\n 0.05586140602827072,\n 0.198002427816391,\n 0.37189847230911255,\n 0.4688553214073181,\n -0.3285660147666931,\n 0.018731718882918358,\n 0.47642427682876587,\n -0.23769721388816833,\n -0.22459551692008972,\n 0.11998675763607025,\n 0.1631166636943817,\n -0.03021230734884739,\n 0.0006783962016925216,\n -0.582108736038208,\n -0.4163672924041748,\n 0.44542446732521057,\n 0.174691841006279,\n 0.06377384811639786,\n 0.06466575711965561,\n -0.05857907608151436,\n 0.14929935336112976,\n -0.11126967519521713,\n -0.144221693277359,\n -1.874097228050232,\n -0.014010274782776833,\n 0.17474065721035004,\n -0.4206511974334717,\n 0.2496553659439087,\n -0.2566078305244446,\n 0.02731264755129814,\n -0.6042962670326233,\n -0.015936043113470078,\n -0.03380664438009262,\n -0.016844576224684715,\n 0.07768023759126663,\n -0.19114601612091064,\n -0.019910180941224098,\n 0.7574723362922668,\n -0.28770336508750916,\n 0.002600799547508359,\n -0.36737334728240967,\n 0.004277372267097235,\n -0.15065494179725647,\n 0.33842551708221436,\n 0.19543682038784027,\n 0.07134147733449936,\n 0.29697418212890625,\n -0.38647037744522095,\n 0.7689567804336548,\n 0.1591203361749649,\n -0.27306583523750305,\n 0.0781339779496193,\n 0.07815150916576385,\n -0.4911087155342102,\n 0.17273107171058655,\n -0.20192518830299377,\n 0.03607308864593506,\n 0.1063367947936058,\n -0.2673143446445465,\n 0.17158426344394684,\n -0.35504817962646484,\n -0.344564825296402,\n 0.0907149389386177,\n 0.0879380851984024,\n -0.031214967370033264,\n -0.4650135934352875,\n 0.368132621049881,\n -0.22880227863788605,\n 0.02313709259033203,\n 0.2059018611907959,\n 0.0886535495519638,\n 0.14711466431617737,\n -0.19193041324615479,\n 0.05568353459239006,\n -0.03175397589802742,\n 0.028525065630674362,\n 0.038188543170690536,\n -0.16180956363677979,\n 0.22967295348644257,\n 0.1790175437927246,\n -0.48071449995040894,\n 0.07288710027933121,\n -0.09362341463565826,\n -0.08880588412284851,\n -0.09899266809225082,\n 0.16958793997764587,\n 0.19177334010601044,\n 0.10067665576934814,\n -0.06789501011371613,\n 0.38921135663986206,\n 0.3168383836746216,\n 0.30702218413352966,\n -0.20801472663879395,\n -0.11692812293767929,\n -0.4028892517089844,\n 0.43391913175582886,\n -0.3823262155056,\n 0.029079746454954147,\n -0.3229360580444336,\n 0.18703722953796387,\n -0.2856178879737854,\n 0.008204245939850807,\n -0.11316367238759995,\n -0.1758439987897873,\n 0.1452414095401764,\n 0.4060892164707184,\n -0.26603153347969055,\n -0.48264965415000916,\n -0.3613775372505188,\n -0.11348666995763779,\n -0.024548238143324852,\n -0.1140439361333847,\n 0.1647636890411377,\n 0.08925215154886246,\n 0.083971306681633,\n 0.014349346980452538,\n -1.0160118341445923,\n 0.047736115753650665,\n -0.30743616819381714,\n 0.49861034750938416,\n 0.23279747366905212,\n 0.24104531109333038,\n -0.3071700930595398,\n 0.03616870567202568,\n 0.2753760516643524,\n -0.0051049948669970036,\n 0.43457159399986267,\n 0.04796813055872917,\n -0.21487340331077576,\n 0.07976184785366058,\n -0.30820897221565247,\n -0.29511499404907227,\n -0.08191969990730286,\n -0.0776844173669815,\n -0.307675302028656,\n -0.4364776611328125,\n 0.17922604084014893,\n 0.8349432945251465,\n -0.3056882321834564,\n 0.18098440766334534,\n 0.2783004641532898,\n -0.34636205434799194,\n -0.25833359360694885,\n 0.11705642938613892,\n 0.1080063208937645,\n -0.1371055543422699,\n -0.1614413857460022,\n 0.24965301156044006,\n 0.2647954821586609,\n 0.05573832243680954,\n -0.3255719840526581,\n -3.1850757598876953,\n -0.24315276741981506,\n -0.24408245086669922,\n -0.05200626701116562,\n -0.02447439357638359,\n -0.2555481791496277,\n 0.189299076795578,\n 0.059048254042863846,\n -0.1557050198316574,\n 0.07537050545215607,\n 0.041549962013959885,\n -0.5603772401809692,\n 0.4080444276332855,\n 0.19681209325790405,\n 0.012813198380172253,\n 0.1114138588309288,\n 0.5356304049491882,\n 0.23875203728675842,\n -0.5848838686943054,\n 0.5462206602096558,\n -0.0057206167839467525,\n 0.07606957852840424,\n 0.2793582081794739,\n -0.10293960571289062,\n 0.38277608156204224,\n 0.2262859344482422,\n 0.05636628717184067,\n -0.06104278564453125,\n -0.2537006437778473,\n 0.09591098874807358,\n -0.16637292504310608,\n 0.011376905255019665,\n -0.2406105101108551,\n 0.14494559168815613,\n -0.014283436350524426,\n -0.08710573613643646,\n 0.3794310390949249,\n -0.0880710557103157,\n 0.2104409635066986,\n 0.30901649594306946,\n -0.09335652738809586,\n 0.06105396896600723,\n 0.03608337417244911,\n 0.17753829061985016,\n 0.2589034140110016,\n -0.11206027120351791,\n 0.20615868270397186,\n -0.1853814423084259,\n 0.3422437012195587,\n 0.23874859511852264,\n 0.13686683773994446,\n -0.20259511470794678,\n 0.22982445359230042,\n 0.0039894236251711845,\n 0.25271645188331604,\n -0.18843290209770203,\n 0.2031325399875641,\n 0.1655677855014801,\n 0.18091461062431335,\n 0.07688649743795395,\n 0.5307149887084961,\n -0.23812279105186462,\n 0.021304065361618996,\n 0.31116849184036255,\n -0.3913962244987488,\n -0.1454274207353592,\n -0.12034139782190323,\n -0.4556726813316345,\n -0.17914056777954102,\n 0.39644360542297363,\n -0.38605833053588867,\n -0.23565351963043213,\n 0.040015291422605515,\n -0.7240340113639832,\n -0.5501312017440796,\n 0.3933050334453583,\n 0.05464881658554077,\n 0.1656615436077118,\n 0.3012602925300598,\n -0.47815245389938354,\n -0.08488081395626068,\n -0.2250688076019287,\n 0.007290607783943415,\n 0.4402923583984375,\n -0.1665392965078354,\n 0.137118399143219,\n 0.16348595917224884,\n -0.3609887957572937,\n -0.11324255168437958,\n 0.0391559973359108,\n 0.20329520106315613,\n 0.2779572606086731,\n 0.35877349972724915,\n 0.09932132810354233,\n 0.17128893733024597,\n -0.08966364711523056,\n 0.2936386466026306,\n -0.7068721652030945,\n 0.24182072281837463,\n -0.31637316942214966,\n -0.43411001563072205,\n -0.20983240008354187,\n 0.4616815447807312,\n 0.098177470266819,\n -0.01864473894238472,\n 0.12333767116069794,\n -0.4165939390659332,\n 0.32773861289024353,\n 0.1375812292098999,\n 0.16336534917354584,\n 0.09184495359659195,\n 0.03871886804699898,\n 0.06247769668698311,\n -0.014035421423614025,\n 0.35159769654273987,\n -0.36943286657333374,\n -0.0801418274641037,\n 0.7178331613540649,\n -0.07767429947853088,\n 0.4113802909851074,\n -0.2254979908466339,\n 0.10460054874420166,\n -0.14710840582847595,\n 0.20120958983898163,\n -0.002541163470596075,\n -0.060076139867305756,\n 0.045459143817424774,\n -0.3029685318470001,\n -0.17855225503444672,\n -0.3137038052082062,\n -0.05004113167524338,\n 0.016671111807227135,\n 0.2299046516418457,\n -0.5765646696090698,\n -0.015235507860779762,\n -0.0468110665678978,\n 0.031035780906677246,\n -0.1278778314590454,\n 0.14466026425361633,\n 0.507269024848938,\n 0.2788441777229309,\n 0.024589329957962036,\n -0.5121592879295349,\n 0.23970241844654083,\n 0.13106617331504822,\n 0.37455788254737854,\n -0.02280101180076599,\n 0.2536669969558716,\n 0.1664210855960846,\n 0.4565128684043884,\n -0.1241164579987526,\n -0.05807900428771973,\n 0.3654821813106537,\n -0.230851411819458,\n 0.18929404020309448,\n -0.15027417242527008,\n 0.180420383810997,\n -0.18751952052116394,\n -0.19960863888263702,\n -0.38007259368896484,\n -0.08560223132371902,\n 0.056791383773088455,\n -0.08416762202978134,\n 0.12692773342132568,\n -0.2663659453392029,\n 0.4093421399593353,\n 0.11855468899011612,\n -0.2609441876411438,\n -0.42190369963645935,\n 0.018886249512434006,\n 0.18638230860233307,\n 0.030699169263243675,\n -0.13148723542690277,\n -0.4366440176963806,\n -0.45372071862220764,\n 0.09355075657367706,\n -0.20771977305412292,\n -0.4917020797729492,\n 0.08899544179439545,\n 0.07337286323308945,\n 0.2615625262260437,\n -0.3092290461063385,\n 0.0780760794878006,\n 0.315208375453949,\n 0.4209819734096527,\n 0.11897419393062592,\n -0.19177675247192383,\n -0.11777303367853165,\n 0.2144332379102707,\n 0.26000919938087463,\n 0.3353390097618103,\n 0.20586749911308289,\n 0.14128993451595306,\n -0.21472887694835663,\n -0.3714120388031006,\n -0.12207157909870148,\n 0.2115665227174759,\n -0.020834505558013916,\n 0.39207467436790466,\n 0.12979404628276825,\n 0.31706541776657104,\n 0.015000266022980213,\n 0.1282484233379364,\n 0.2487044632434845,\n 0.20949402451515198,\n -0.005866652820259333,\n 0.3374544382095337,\n -0.0023118467070162296,\n -0.3201432228088379,\n 0.02107180282473564,\n 0.07729528844356537,\n -0.5500381588935852,\n -0.039617739617824554,\n -0.29045572876930237,\n 0.13390497863292694,\n -0.04982471466064453,\n -0.11247436702251434,\n -0.17658574879169464,\n 0.05078141763806343,\n -0.17655345797538757,\n -0.23586316406726837,\n -0.23435544967651367,\n -0.18360473215579987,\n -0.16156122088432312,\n -0.24069444835186005,\n -0.30867427587509155,\n -0.060747742652893066,\n -0.08617251366376877,\n -0.346278578042984,\n -0.2015550136566162,\n 0.13868221640586853,\n 0.08268669992685318,\n -0.004450214095413685,\n -0.09627605974674225,\n 0.2212754786014557,\n 0.30199360847473145,\n -0.5228806734085083,\n 0.08805771917104721,\n 0.41112393140792847,\n -0.33266782760620117,\n -0.16359567642211914,\n -0.4908908009529114,\n -0.1281021386384964,\n -0.4356963038444519,\n 0.13914115726947784,\n 0.10619895160198212,\n 0.009412562474608421,\n 0.4029324948787689,\n -0.25812697410583496,\n 0.10736062377691269,\n -0.06302111595869064,\n -0.15045057237148285,\n -0.08120999485254288,\n -0.556869626045227,\n 0.24915051460266113,\n -0.8963121175765991,\n -0.26155248284339905,\n 0.224275141954422,\n -0.12486572563648224,\n -0.14950168132781982,\n 0.023092543706297874,\n 0.32137101888656616,\n -0.0020614266395568848,\n -0.05723245069384575,\n -0.04934069514274597,\n 0.3897772431373596,\n 0.12749600410461426,\n 0.07983161509037018,\n 0.291098415851593,\n 0.18380200862884521,\n -0.29809361696243286,\n 0.012471998110413551,\n 0.01727420650422573,\n 0.4861001968383789,\n -0.17479050159454346,\n -0.027577757835388184,\n 0.11504293978214264,\n -0.4390411972999573,\n -0.156858891248703,\n -0.048401087522506714,\n 0.7641364932060242,\n 0.5595901012420654,\n 0.07940831780433655,\n 0.0489858016371727,\n -0.03691709414124489,\n -0.254279226064682,\n -0.04194291681051254,\n 0.0939379632472992,\n -0.3795467019081116,\n 0.0719146579504013,\n 0.5841690897941589,\n -0.05967414379119873,\n -0.020419087260961533,\n 0.2210724800825119,\n 0.18191742897033691,\n 0.06942017376422882,\n -0.10970593988895416,\n 0.02834058366715908,\n -0.6904433965682983,\n 0.3333301544189453,\n -0.47775977849960327,\n 0.5629856586456299,\n 0.03690315783023834,\n -0.34557607769966125,\n 0.13196882605552673,\n 0.005466270260512829,\n -0.046380698680877686,\n -0.6279757618904114,\n 0.18440485000610352,\n 0.30001217126846313,\n -0.2782984673976898,\n -0.29854756593704224,\n 0.022003132849931717,\n 0.6127959489822388,\n -0.42702561616897583,\n 0.24618513882160187,\n 0.3069060146808624,\n -0.3237451910972595,\n -0.15776214003562927,\n 0.34702935814857483,\n -0.03648269176483154,\n 0.21007171273231506,\n 0.48598676919937134,\n -0.23030126094818115,\n 0.5188769102096558,\n 0.414620578289032,\n -0.6934993267059326,\n 0.14528021216392517,\n 0.008247291669249535,\n 0.13770362734794617,\n 0.12919968366622925,\n 0.18329426646232605,\n -0.4613169729709625,\n 0.28889185190200806,\n -0.11847921460866928,\n -0.27036502957344055,\n 0.22077202796936035,\n 0.2724918723106384,\n -0.07383151352405548,\n 0.061443328857421875,\n 0.3491309881210327,\n -0.23457014560699463,\n 0.21970562636852264,\n 0.08926664292812347,\n -0.022917937487363815,\n -0.43303728103637695,\n 0.11708199977874756,\n -0.20496726036071777,\n 0.1965494453907013,\n -0.375702828168869,\n 0.2494441270828247,\n 0.11636622995138168,\n 0.2307715117931366,\n -0.07371235638856888,\n 0.046123333275318146,\n -0.06996922194957733,\n -0.03802754357457161,\n 0.11119697242975235,\n 0.20053395628929138,\n -0.8881515264511108,\n 0.01489101629704237,\n 0.06068335846066475,\n 0.016705071553587914,\n -0.4435242712497711,\n 0.3088405728340149,\n 0.19420623779296875,\n 0.0783306360244751,\n 0.11134274303913116,\n -0.20625105500221252,\n 0.47944918274879456,\n 0.0948304757475853,\n 0.18656136095523834,\n -0.06177862361073494,\n -0.13435065746307373,\n 0.263837069272995,\n 0.0443335622549057,\n 0.1961301863193512,\n -0.026736080646514893,\n -0.21887537837028503,\n -0.11000722646713257,\n -0.12308748066425323,\n 0.1682289093732834,\n -0.36947399377822876,\n -0.5245373845100403,\n 0.574881911277771,\n -0.2507259249687195,\n 0.01676614210009575,\n -0.44062939286231995,\n 0.1977948695421219,\n -0.1441343128681183,\n 0.5193415880203247,\n -0.3875125050544739,\n -0.03960005193948746,\n -0.09548687934875488,\n 0.040065180510282516,\n -0.19045811891555786,\n -0.10545488446950912,\n 0.26197466254234314,\n 0.14204363524913788,\n 0.1377134770154953,\n 0.3982456624507904,\n -0.018898671492934227,\n -0.46056804060935974,\n 0.0175954457372427,\n 0.10671545565128326,\n -0.04263320565223694,\n 0.04306446388363838,\n 0.4687792658805847,\n -0.25642067193984985,\n -0.3135685324668884,\n -0.03648040443658829,\n -0.034415073692798615,\n -0.8937336206436157,\n 0.2679235339164734,\n 0.17985719442367554,\n -0.2118675708770752,\n -0.19912955164909363,\n 0.023903513327240944,\n -0.22654207050800323,\n -0.2586623728275299,\n 0.027447253465652466,\n -0.1917460858821869,\n 0.022061049938201904,\n 0.06387905776500702,\n -0.44702115654945374,\n -0.16203387081623077,\n -0.24978426098823547,\n 0.24902944266796112,\n 0.0036243319045752287,\n -0.4159727692604065,\n -0.23602910339832306,\n 0.2364286631345749,\n -0.028759997338056564,\n 0.14802832901477814,\n 0.19573044776916504,\n 0.020183313637971878,\n 0.03174861520528793,\n 0.1614380180835724,\n -0.09191383421421051,\n -0.12607327103614807,\n 0.03323235362768173,\n 0.06951407343149185,\n 0.33404025435447693,\n 0.20414653420448303,\n -2.7974278926849365,\n -0.17933902144432068,\n 0.0015476227272301912,\n 0.32003650069236755,\n 0.17668691277503967,\n -0.19913537800312042,\n 0.2555692195892334,\n -0.11419615894556046,\n -0.0028838932048529387,\n -0.10916507244110107,\n 0.08797872066497803,\n -0.20501315593719482,\n 0.10887274891138077,\n -0.31972652673721313,\n 0.2089846134185791,\n -0.2573690116405487]"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_1['genre_embeddings'].iloc[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-25T17:56:42.249568Z",
     "start_time": "2024-10-25T17:56:42.246404Z"
    }
   },
   "id": "3926f5926b3364c3"
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "          id                                           name  \\\n7776  849177  Shadow of the Tomb Raider: Definitive Edition   \n\n                                            description              genres  \\\n7776  In Shadow of the Tomb Raider Definitive Editio...  [Action,Adventure]   \n\n                                        desc_embeddings  \\\n7776  [0.01750553771853447, 0.05562837794423103, -0....   \n\n                                       genre_embeddings  \n7776  [-0.10142902284860611, -0.061262160539627075, ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n      <th>description</th>\n      <th>genres</th>\n      <th>desc_embeddings</th>\n      <th>genre_embeddings</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7776</th>\n      <td>849177</td>\n      <td>Shadow of the Tomb Raider: Definitive Edition</td>\n      <td>In Shadow of the Tomb Raider Definitive Editio...</td>\n      <td>[Action,Adventure]</td>\n      <td>[0.01750553771853447, 0.05562837794423103, -0....</td>\n      <td>[-0.10142902284860611, -0.061262160539627075, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-25T17:57:13.362102Z",
     "start_time": "2024-10-25T17:57:13.353107Z"
    }
   },
   "id": "7d7aa3f8ddaca149"
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "#Function to calculate similarity based on desc_embeddings and genre_embeddings\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def weighted_similarity(game_1: list, game_2:list, desc_weight=0.8):\n",
    "    similarity_desc = cosine_similarity(game_1[0], game_2[0])\n",
    "    similarity_genre = cosine_similarity(game_1[1], game_2[1])\n",
    "    return desc_weight * similarity_desc + (1 - desc_weight) * similarity_genre"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-25T18:01:23.479540Z",
     "start_time": "2024-10-25T18:01:23.475318Z"
    }
   },
   "id": "8527f0f5fa830511"
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[ 1.75055377e-02  5.56283779e-02 -1.94122698e-02  2.07415745e-02\n -1.32416077e-02  5.34118153e-02 -6.43035769e-02  7.52757676e-03\n -5.63897975e-02  1.91594251e-02  2.75359172e-02  4.71493229e-02\n  3.78632173e-03  9.03100893e-03  2.08571311e-02 -3.01131532e-02\n  9.33512207e-03  1.23839052e-02 -1.05983384e-01  1.92305613e-02\n -3.98714468e-02 -2.23607779e-03 -1.06690507e-02 -3.29926908e-02\n  6.78968951e-02  4.47034370e-04  1.02569526e-02  8.53046402e-02\n -2.42942758e-02 -4.22537103e-02  2.13581454e-02 -6.81235790e-02\n  6.13739453e-02  1.03297585e-03  2.11824522e-06 -4.35234755e-02\n -3.03891841e-02 -2.69645955e-02 -5.83464727e-02  2.61926930e-03\n -4.89954427e-02  6.23812564e-02  6.49365364e-03 -5.38720079e-02\n  4.18762155e-02  3.03339865e-03  5.21701723e-02  3.33647393e-02\n  2.31434479e-02 -2.72726398e-02  2.69887364e-03 -4.55447845e-02\n -3.23101841e-02 -2.02460699e-02  6.93363994e-02 -9.54215357e-05\n -1.64552648e-02 -2.34200549e-03  3.46095972e-02  2.43450943e-02\n  1.15478728e-02  2.63334066e-02 -9.68375988e-03  4.58990447e-02\n  1.08244531e-02  1.11365691e-02  7.83828795e-02 -1.87863130e-02\n  2.73578335e-02  1.93592731e-03 -4.31461409e-02 -2.16794796e-02\n  1.72028560e-02  6.20734915e-02 -3.64055634e-02 -1.06885899e-02\n -2.67820712e-02 -9.41133694e-05 -1.61882397e-02 -2.57876217e-02\n -4.52608690e-02  4.78206798e-02  2.32147183e-02 -5.63424220e-03\n  2.80888136e-02  2.41418090e-02 -4.15016152e-03 -1.89846363e-02\n  9.58265830e-03  7.35923275e-03  6.15746900e-03  3.20974663e-02\n -7.36829489e-02  3.61104170e-03 -4.99962419e-02 -1.99916791e-02\n  4.39937972e-03  3.44544500e-02  5.23232184e-02  4.60057147e-02\n  4.58504222e-02  1.20550534e-02 -3.87725234e-02 -4.09728847e-03\n -8.73158500e-03 -2.16308213e-03  2.88430974e-02 -4.45473716e-02\n  4.03499231e-02  5.16554490e-02  5.47201857e-02  1.64286960e-02\n -4.36726846e-02  3.65993343e-02 -3.50808315e-02 -4.29029064e-03\n  4.95437495e-02 -1.59630906e-02  2.03102250e-02 -2.11584382e-02\n -5.87777160e-02 -2.49620378e-02 -1.01280222e-02  1.48059917e-03\n  3.87898348e-02 -1.05354272e-01 -2.85500512e-02  1.90450612e-03\n -1.83453038e-02 -7.42252916e-03 -3.76010202e-02 -4.57219854e-02\n  1.78975351e-02  3.67265083e-02  2.24780478e-02  2.68501248e-02\n  5.79691678e-02 -1.26216784e-02 -1.89405642e-02  3.08601409e-02\n  2.71643922e-02 -2.32878160e-02 -7.68794939e-02 -1.37571665e-02\n  1.15125878e-02 -2.91241724e-02 -2.00505201e-02  2.39692889e-02\n  4.01984528e-03 -3.94526012e-02  9.85284671e-02  2.42172126e-02\n  6.52957335e-02 -1.35964947e-02  6.11079000e-02  2.67519020e-02\n  1.94142684e-02  3.13755795e-02 -1.42329419e-02  8.12539384e-02\n -7.62493024e-03  5.93462475e-02 -5.74019998e-02  1.71303470e-02\n  4.79724118e-03  1.15545867e-02 -4.50795237e-03  5.39291231e-03\n  3.69404145e-02  5.09074964e-02 -6.85628802e-02 -4.68259789e-02\n -1.68924574e-02 -2.81217638e-02 -2.93411054e-02 -5.21519743e-02\n -4.25249264e-02 -4.81506847e-02  3.72951217e-02 -1.49448833e-03\n  5.18471487e-02 -4.48582470e-02  1.85293220e-02 -4.97515313e-02\n  7.08907843e-02 -3.29835992e-03 -2.87124477e-02 -2.54332684e-02\n  1.53995762e-02 -1.97981186e-02  1.90643650e-02 -1.43577494e-02\n  7.55839497e-02  7.12002218e-02  2.91497260e-03  2.77490672e-02\n -2.43456122e-02  2.84975283e-02  4.33057267e-03 -4.78617288e-02\n -1.11867127e-03 -1.30365696e-02  3.99887152e-02 -3.94737497e-02\n -5.87339047e-03 -2.73625329e-02 -3.73330116e-02  3.18503997e-04\n  3.17486119e-03  5.19504882e-02 -4.55030277e-02  4.11404967e-02\n  2.30738427e-02 -2.46647839e-02  9.64821223e-03 -3.35802957e-02\n -2.78133736e-03  1.21895615e-02  6.72177505e-03 -9.74690821e-03\n -1.79658495e-02  5.68567659e-04  7.04712840e-03 -3.13434936e-02\n -1.41007295e-02 -3.62862572e-02 -2.98834536e-02 -8.61929730e-03\n  8.38584825e-03  4.45394143e-02 -3.35683078e-02 -1.31782368e-02\n -3.75523022e-03 -3.16639729e-02 -5.17513156e-02 -3.71569023e-02\n  7.64242373e-03  1.25745833e-01  5.65760443e-03 -3.87276635e-02\n -1.19202712e-04  6.27947226e-02  2.50384361e-02  3.44394185e-02\n  1.18035423e-02 -2.74101608e-02  4.66977209e-02 -4.46320686e-04\n -2.36276910e-03 -4.78680730e-02  6.96524512e-04 -2.57363562e-02\n  3.26252513e-04 -4.47232984e-02 -2.21615303e-02  1.10112950e-02\n -1.49798649e-03  1.55940205e-02  1.77136716e-02 -3.31055485e-02\n -1.96988080e-02  5.81257604e-03 -9.16397106e-03 -4.70293239e-02\n -3.93853746e-02  8.84819124e-03  1.15703242e-02  3.93209234e-03\n  3.72772501e-03 -1.80939715e-02  7.24904612e-02  2.29876488e-02\n  1.43688079e-02 -1.01736477e-02 -7.79949967e-03 -1.90648134e-03\n  1.20839579e-02 -1.13552902e-02 -2.89853755e-02  4.12103516e-04\n  4.70356382e-02  7.99963400e-02 -1.10310540e-02  1.01776654e-02\n  9.58971586e-03  5.16173840e-02  2.66598575e-02 -6.72822297e-02\n  3.09747681e-02 -2.82663126e-02  3.87661979e-02  5.11990581e-03\n -1.59728024e-02 -5.70112132e-02 -2.61767884e-03 -3.98402661e-03\n -1.18022915e-02 -2.53608800e-03  1.22967632e-02  4.89425063e-02\n -4.23012505e-04  3.49215753e-02  3.16790454e-02 -5.27992100e-03\n  2.76279394e-02 -4.38188687e-02 -4.75088656e-02 -2.55370624e-02\n  3.76274250e-02 -2.63154972e-02 -1.89469233e-02 -6.74046902e-03\n -1.35034195e-03 -6.52198121e-02  8.39979108e-03 -1.62736177e-02\n  3.49826850e-02 -4.31799032e-02  1.89671777e-02 -1.77272558e-02\n -5.10789230e-02  3.87125090e-02 -3.85339707e-02  5.68695599e-03\n -3.38745723e-03 -4.37672287e-02  5.14479168e-02 -3.68278027e-02\n  1.62972398e-02  2.32295673e-02  3.56925987e-02 -2.67856251e-02\n -1.65193770e-02 -3.13398847e-03 -2.65776385e-02 -7.93772191e-03\n -1.77925434e-02 -6.11093827e-02 -1.47004169e-03 -1.50916204e-02\n  2.49094255e-02  4.33518784e-03  1.06231943e-02  4.43444587e-02\n -7.62529224e-02 -3.08764428e-02 -3.73066142e-02  4.93864305e-02\n  3.98838222e-02 -8.61893687e-03 -3.29699814e-02  7.85417855e-03\n  6.85432507e-03 -1.71071757e-02  4.18841690e-02 -7.64539391e-02\n  4.33914252e-02  8.79432037e-02  4.75995429e-02 -4.11684550e-02\n -1.09945647e-02  2.09075715e-02 -9.77121294e-02 -6.45583123e-03\n  1.63567420e-02 -2.51106378e-02  3.48496176e-02 -6.63355645e-03\n -1.98882334e-02  2.15651700e-03 -7.01613724e-02 -3.54075842e-02\n  2.60366164e-02  1.00997146e-02  2.49071792e-02 -5.28508518e-03\n -2.52017789e-02 -2.96847839e-02  2.70613823e-02  1.64177660e-02\n -3.10335848e-02 -1.18135720e-01  4.26516077e-03  2.44129412e-02\n  5.51338028e-03  3.43936384e-02 -6.79047080e-05  4.31150496e-02\n -7.01375818e-03 -5.16205281e-03  2.45724395e-02 -1.21860765e-01\n  4.63019498e-02  8.55250582e-02 -3.33464448e-03 -5.57449721e-02\n -1.09275170e-02  1.73359644e-02 -1.91021003e-02 -2.87620630e-02\n -4.85176966e-03  2.42441148e-02  6.03003725e-02  7.34636374e-03\n -6.58913329e-02 -2.17981040e-02  4.02666144e-02  2.50547007e-03\n  2.70507429e-02  1.71557423e-02  1.69114247e-02  1.55144110e-02\n  2.24949438e-02  1.09874420e-02  1.88002046e-02  4.53582965e-03\n  1.79268373e-03  6.99624093e-03 -4.80596647e-02  3.08817774e-02\n  1.36245275e-02 -3.20214778e-02 -4.05726694e-02 -4.72657979e-02\n  2.96804346e-02 -5.52344956e-02  5.94026595e-03  2.85609043e-04\n -1.22749843e-02 -1.23383822e-02 -9.27929673e-03 -9.63241700e-03\n  1.30024459e-02  7.94234052e-02 -1.35290939e-02 -4.00234535e-02\n  1.24088004e-02 -3.00377365e-02  4.62444276e-02 -2.15973763e-04\n -1.60418767e-02 -2.88399849e-02  2.04387736e-02 -6.75940374e-03\n -1.50114838e-02 -7.63812568e-03 -1.75065994e-02 -8.69040787e-02\n -7.46335238e-02  1.63677670e-02  6.80913043e-04  5.05806543e-02\n -2.56011970e-02 -3.79000306e-02 -7.58246258e-02  1.03536071e-02\n -5.44604994e-02 -7.47085586e-02  1.41446544e-02  1.66898891e-02\n  1.02182794e-02  8.68633017e-03 -3.56266238e-02  1.26684457e-02\n -5.40778413e-02  6.87354133e-02 -7.79730007e-02  2.60117278e-03\n -4.27175220e-03  1.09971752e-02  8.92479531e-03  9.24521126e-04\n  1.29508565e-03 -1.73942912e-02 -1.30676609e-02 -3.52515676e-03\n -2.56819651e-02  1.01649761e-02 -9.04367026e-03  3.98797961e-03\n -4.65250090e-02  2.84145325e-02  3.74951004e-03  2.65063886e-02\n  2.21090503e-02  3.65748629e-02 -3.23049016e-02  3.35518597e-03\n  1.74077172e-02  3.69972992e-03 -7.29519175e-03  1.76396146e-02\n  2.71766260e-02  5.31552583e-02  2.82585938e-02  1.83973126e-02\n -6.16295226e-02 -4.21744287e-02  9.34302434e-02 -5.66754304e-02\n -8.13768897e-03  1.20670879e-02 -1.97449364e-02 -1.17568029e-02\n -1.11968825e-02 -3.05508953e-02  1.13354316e-02 -1.08850673e-02\n -1.66359562e-02 -2.29499186e-03  3.59796616e-03 -1.24789113e-02\n -2.20422409e-02 -3.37510109e-02  4.77207340e-02 -1.73705351e-02\n  3.50818038e-02 -8.80621467e-03  2.84616519e-02  2.71866564e-02\n -1.96970031e-02  1.65863372e-02  1.19530444e-03 -2.92669181e-02\n  1.72919277e-02 -3.13186981e-02  6.01529656e-03  2.25897748e-02\n  1.74147226e-02 -4.12616320e-02  5.85532188e-03  5.35180680e-02\n  5.58125898e-02  4.00458276e-02  1.16849868e-02  2.41086837e-02\n -4.78722388e-03  6.64723441e-02 -1.01832021e-03 -5.69077581e-02\n  2.13917177e-02  8.82170163e-03  6.24029078e-02  3.60345878e-02\n -4.93079014e-02  3.41875777e-02 -8.86109378e-03  1.29644796e-02\n  4.90984730e-02 -2.05017123e-02 -2.73573841e-03 -7.69184530e-02\n -5.38677387e-02 -5.16973510e-02  5.85781783e-02 -6.15020885e-33\n  1.16113657e-02 -1.16522266e-02 -3.68662900e-03 -1.74251944e-03\n -5.05884662e-02  8.76333285e-03  3.56312562e-03  6.98931189e-03\n -6.41284930e-03 -1.86328758e-02  3.21220830e-02  1.24927703e-02\n -4.23061568e-03  3.09763476e-02 -1.51065318e-02  3.31984386e-02\n  2.90168673e-02  5.64335845e-02 -3.94090032e-03 -1.67538393e-02\n -1.60394367e-02  6.56500086e-03  7.80047663e-03 -5.53862937e-02\n  2.41907407e-02 -1.43446755e-02  7.50727253e-03 -4.65504033e-03\n  3.25727686e-02  2.62190010e-02  8.46764352e-03 -5.15125692e-02\n  9.45906062e-03 -1.18356952e-02  1.28131136e-02 -1.72146782e-02\n -4.93238345e-02  1.00119617e-02  8.62771831e-03  4.26262096e-02\n -3.32272314e-02 -9.69304815e-02  6.95233792e-03 -1.27162915e-02\n  2.75861993e-02 -9.20861773e-03 -6.91513065e-03 -1.66155826e-02\n  1.17112892e-02 -9.74554345e-02 -5.21131903e-02 -9.47220717e-03\n  3.43528576e-03  2.41525546e-02  1.26525545e-02  4.03679535e-02\n -2.65859012e-02 -5.17518669e-02  5.76242618e-02  2.99946070e-02\n -2.00340375e-02 -3.26884687e-02 -1.69149954e-02 -2.97283176e-02\n  1.67640075e-02 -1.28456317e-02 -1.58242732e-02 -2.66360641e-02\n -5.21737263e-02  5.08641936e-02  1.45849222e-02  1.24559936e-03\n  2.71272510e-02  9.66960266e-02  1.28149716e-02 -7.09765358e-03\n -3.47179249e-02  2.49626171e-02  9.30798799e-03 -6.89559523e-03\n  5.71426079e-02  1.92884952e-02 -7.53424615e-02  4.01675440e-02\n -3.81068303e-03  7.99634978e-02 -1.42071126e-02 -2.37909760e-02\n  3.46525386e-02 -1.49838049e-02 -5.93865998e-02 -1.01487676e-03\n -5.21531254e-02 -4.39878404e-02  6.97664022e-02  4.12533320e-02\n  3.63477468e-02 -5.34341447e-02  2.73667816e-02 -1.54123651e-02\n  1.28830358e-01  7.66366394e-03  6.94627780e-03 -2.11688075e-02\n  2.91196839e-03  7.15040741e-03 -4.08192500e-02  3.41010317e-02\n -5.19427657e-03  9.10451636e-03  2.13447455e-02 -1.83989375e-03\n -1.51564851e-02 -2.17404850e-02  7.68181449e-03 -6.85032234e-02\n  8.14647134e-03 -2.62931120e-02  1.55845918e-02  3.05560641e-02\n  5.28977811e-02  7.82851651e-02 -3.93773010e-03  3.07237674e-02\n  2.89140977e-02  2.19724625e-02 -1.06112398e-02  3.69371325e-02\n -7.06979036e-02 -3.79267968e-02 -5.31094931e-02  3.52745205e-02\n  2.81861560e-07 -1.52249318e-02  6.03180937e-02  7.06116110e-03\n  4.16149497e-02 -9.37373901e-04 -4.28261347e-02  4.59849685e-02\n  1.54953236e-02 -4.57429178e-02  1.29765896e-02  5.25619602e-03\n  4.11267579e-02 -2.49698292e-02  2.63094231e-02 -8.85944907e-03\n -8.62354562e-02  2.87570357e-02 -7.12938327e-03 -3.27352025e-02\n -2.63189338e-02  1.20814390e-01  3.18851471e-02 -2.03403030e-02\n -3.10703199e-02 -1.14337625e-02  1.90644227e-02 -5.87653648e-03\n -8.22500233e-03  2.19477508e-02 -1.59391724e-02 -2.16257526e-03\n  2.61115339e-02 -2.44061667e-02 -8.69395137e-02  3.89402770e-02\n -6.22375831e-02  5.04101887e-02  3.79639193e-02 -1.26464653e-03\n -5.33055551e-02  9.57892183e-03  2.43446138e-02 -4.06210357e-03\n -6.61535338e-02  2.10537221e-02  1.14850119e-01 -9.05924942e-03\n -1.07338741e-01 -5.24651557e-02  1.36263892e-02  2.65873279e-02\n -1.45666003e-02 -1.30288638e-02 -1.77523028e-02 -6.60713995e-03\n -2.56726220e-02  1.16631866e-03 -1.02037340e-02  1.63282137e-02\n  1.04058862e-01  9.50932782e-03  1.87795404e-02  4.30704793e-03\n -1.73487943e-02 -9.20979492e-03 -7.24763945e-02 -1.88865175e-03\n  2.22371733e-34  2.46033650e-02  1.06864306e-03  5.14988936e-02\n -2.97110230e-02  2.07253955e-02  1.32365441e-02 -2.92844046e-02\n -4.47769416e-03  2.19273730e-03  8.43835715e-03 -7.55130954e-04].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[79], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m sim_1_2 \u001B[38;5;241m=\u001B[39m weighted_similarity(g_1[[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdesc_embeddings\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgenre_embeddings\u001B[39m\u001B[38;5;124m'\u001B[39m]]\u001B[38;5;241m.\u001B[39mvalues[\u001B[38;5;241m0\u001B[39m], g_2[[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdesc_embeddings\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgenre_embeddings\u001B[39m\u001B[38;5;124m'\u001B[39m]]\u001B[38;5;241m.\u001B[39mvalues[\u001B[38;5;241m0\u001B[39m])\n",
      "Cell \u001B[0;32mIn[78], line 4\u001B[0m, in \u001B[0;36mweighted_similarity\u001B[0;34m(game_1, game_2, desc_weight)\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mweighted_similarity\u001B[39m(game_1: \u001B[38;5;28mlist\u001B[39m, game_2:\u001B[38;5;28mlist\u001B[39m, desc_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.8\u001B[39m):\n\u001B[0;32m----> 4\u001B[0m     similarity_desc \u001B[38;5;241m=\u001B[39m cosine_similarity(game_1[\u001B[38;5;241m0\u001B[39m], game_2[\u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m      5\u001B[0m     similarity_genre \u001B[38;5;241m=\u001B[39m cosine_similarity(game_1[\u001B[38;5;241m1\u001B[39m], game_2[\u001B[38;5;241m1\u001B[39m])\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m desc_weight \u001B[38;5;241m*\u001B[39m similarity_desc \u001B[38;5;241m+\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m desc_weight) \u001B[38;5;241m*\u001B[39m similarity_genre\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:213\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    207\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    208\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m    209\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m    210\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m    211\u001B[0m         )\n\u001B[1;32m    212\u001B[0m     ):\n\u001B[0;32m--> 213\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    214\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    215\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[1;32m    217\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[1;32m    219\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[1;32m    220\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    221\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    222\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[1;32m    223\u001B[0m     )\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/metrics/pairwise.py:1679\u001B[0m, in \u001B[0;36mcosine_similarity\u001B[0;34m(X, Y, dense_output)\u001B[0m\n\u001B[1;32m   1635\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Compute cosine similarity between samples in X and Y.\u001B[39;00m\n\u001B[1;32m   1636\u001B[0m \n\u001B[1;32m   1637\u001B[0m \u001B[38;5;124;03mCosine similarity, or the cosine kernel, computes similarity as the\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1675\u001B[0m \u001B[38;5;124;03m       [0.57..., 0.81...]])\u001B[39;00m\n\u001B[1;32m   1676\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1677\u001B[0m \u001B[38;5;66;03m# to avoid recursive import\u001B[39;00m\n\u001B[0;32m-> 1679\u001B[0m X, Y \u001B[38;5;241m=\u001B[39m check_pairwise_arrays(X, Y)\n\u001B[1;32m   1681\u001B[0m X_normalized \u001B[38;5;241m=\u001B[39m normalize(X, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m   1682\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m X \u001B[38;5;129;01mis\u001B[39;00m Y:\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/metrics/pairwise.py:185\u001B[0m, in \u001B[0;36mcheck_pairwise_arrays\u001B[0;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, ensure_2d, copy)\u001B[0m\n\u001B[1;32m    175\u001B[0m     X \u001B[38;5;241m=\u001B[39m Y \u001B[38;5;241m=\u001B[39m check_array(\n\u001B[1;32m    176\u001B[0m         X,\n\u001B[1;32m    177\u001B[0m         accept_sparse\u001B[38;5;241m=\u001B[39maccept_sparse,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    182\u001B[0m         ensure_2d\u001B[38;5;241m=\u001B[39mensure_2d,\n\u001B[1;32m    183\u001B[0m     )\n\u001B[1;32m    184\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 185\u001B[0m     X \u001B[38;5;241m=\u001B[39m check_array(\n\u001B[1;32m    186\u001B[0m         X,\n\u001B[1;32m    187\u001B[0m         accept_sparse\u001B[38;5;241m=\u001B[39maccept_sparse,\n\u001B[1;32m    188\u001B[0m         dtype\u001B[38;5;241m=\u001B[39mdtype,\n\u001B[1;32m    189\u001B[0m         copy\u001B[38;5;241m=\u001B[39mcopy,\n\u001B[1;32m    190\u001B[0m         force_all_finite\u001B[38;5;241m=\u001B[39mforce_all_finite,\n\u001B[1;32m    191\u001B[0m         estimator\u001B[38;5;241m=\u001B[39mestimator,\n\u001B[1;32m    192\u001B[0m         ensure_2d\u001B[38;5;241m=\u001B[39mensure_2d,\n\u001B[1;32m    193\u001B[0m     )\n\u001B[1;32m    194\u001B[0m     Y \u001B[38;5;241m=\u001B[39m check_array(\n\u001B[1;32m    195\u001B[0m         Y,\n\u001B[1;32m    196\u001B[0m         accept_sparse\u001B[38;5;241m=\u001B[39maccept_sparse,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    201\u001B[0m         ensure_2d\u001B[38;5;241m=\u001B[39mensure_2d,\n\u001B[1;32m    202\u001B[0m     )\n\u001B[1;32m    204\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m precomputed:\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1050\u001B[0m, in \u001B[0;36mcheck_array\u001B[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[1;32m   1043\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1044\u001B[0m             msg \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m   1045\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpected 2D array, got 1D array instead:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124marray=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00marray\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1046\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1047\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myour data has a single feature or array.reshape(1, -1) \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1048\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mif it contains a single sample.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1049\u001B[0m             )\n\u001B[0;32m-> 1050\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg)\n\u001B[1;32m   1052\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dtype_numeric \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(array\u001B[38;5;241m.\u001B[39mdtype, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkind\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m array\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;241m.\u001B[39mkind \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUSV\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m   1053\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1054\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnumeric\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m is not compatible with arrays of bytes/strings.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1055\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConvert your data to numeric values explicitly instead.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1056\u001B[0m     )\n",
      "\u001B[0;31mValueError\u001B[0m: Expected 2D array, got 1D array instead:\narray=[ 1.75055377e-02  5.56283779e-02 -1.94122698e-02  2.07415745e-02\n -1.32416077e-02  5.34118153e-02 -6.43035769e-02  7.52757676e-03\n -5.63897975e-02  1.91594251e-02  2.75359172e-02  4.71493229e-02\n  3.78632173e-03  9.03100893e-03  2.08571311e-02 -3.01131532e-02\n  9.33512207e-03  1.23839052e-02 -1.05983384e-01  1.92305613e-02\n -3.98714468e-02 -2.23607779e-03 -1.06690507e-02 -3.29926908e-02\n  6.78968951e-02  4.47034370e-04  1.02569526e-02  8.53046402e-02\n -2.42942758e-02 -4.22537103e-02  2.13581454e-02 -6.81235790e-02\n  6.13739453e-02  1.03297585e-03  2.11824522e-06 -4.35234755e-02\n -3.03891841e-02 -2.69645955e-02 -5.83464727e-02  2.61926930e-03\n -4.89954427e-02  6.23812564e-02  6.49365364e-03 -5.38720079e-02\n  4.18762155e-02  3.03339865e-03  5.21701723e-02  3.33647393e-02\n  2.31434479e-02 -2.72726398e-02  2.69887364e-03 -4.55447845e-02\n -3.23101841e-02 -2.02460699e-02  6.93363994e-02 -9.54215357e-05\n -1.64552648e-02 -2.34200549e-03  3.46095972e-02  2.43450943e-02\n  1.15478728e-02  2.63334066e-02 -9.68375988e-03  4.58990447e-02\n  1.08244531e-02  1.11365691e-02  7.83828795e-02 -1.87863130e-02\n  2.73578335e-02  1.93592731e-03 -4.31461409e-02 -2.16794796e-02\n  1.72028560e-02  6.20734915e-02 -3.64055634e-02 -1.06885899e-02\n -2.67820712e-02 -9.41133694e-05 -1.61882397e-02 -2.57876217e-02\n -4.52608690e-02  4.78206798e-02  2.32147183e-02 -5.63424220e-03\n  2.80888136e-02  2.41418090e-02 -4.15016152e-03 -1.89846363e-02\n  9.58265830e-03  7.35923275e-03  6.15746900e-03  3.20974663e-02\n -7.36829489e-02  3.61104170e-03 -4.99962419e-02 -1.99916791e-02\n  4.39937972e-03  3.44544500e-02  5.23232184e-02  4.60057147e-02\n  4.58504222e-02  1.20550534e-02 -3.87725234e-02 -4.09728847e-03\n -8.73158500e-03 -2.16308213e-03  2.88430974e-02 -4.45473716e-02\n  4.03499231e-02  5.16554490e-02  5.47201857e-02  1.64286960e-02\n -4.36726846e-02  3.65993343e-02 -3.50808315e-02 -4.29029064e-03\n  4.95437495e-02 -1.59630906e-02  2.03102250e-02 -2.11584382e-02\n -5.87777160e-02 -2.49620378e-02 -1.01280222e-02  1.48059917e-03\n  3.87898348e-02 -1.05354272e-01 -2.85500512e-02  1.90450612e-03\n -1.83453038e-02 -7.42252916e-03 -3.76010202e-02 -4.57219854e-02\n  1.78975351e-02  3.67265083e-02  2.24780478e-02  2.68501248e-02\n  5.79691678e-02 -1.26216784e-02 -1.89405642e-02  3.08601409e-02\n  2.71643922e-02 -2.32878160e-02 -7.68794939e-02 -1.37571665e-02\n  1.15125878e-02 -2.91241724e-02 -2.00505201e-02  2.39692889e-02\n  4.01984528e-03 -3.94526012e-02  9.85284671e-02  2.42172126e-02\n  6.52957335e-02 -1.35964947e-02  6.11079000e-02  2.67519020e-02\n  1.94142684e-02  3.13755795e-02 -1.42329419e-02  8.12539384e-02\n -7.62493024e-03  5.93462475e-02 -5.74019998e-02  1.71303470e-02\n  4.79724118e-03  1.15545867e-02 -4.50795237e-03  5.39291231e-03\n  3.69404145e-02  5.09074964e-02 -6.85628802e-02 -4.68259789e-02\n -1.68924574e-02 -2.81217638e-02 -2.93411054e-02 -5.21519743e-02\n -4.25249264e-02 -4.81506847e-02  3.72951217e-02 -1.49448833e-03\n  5.18471487e-02 -4.48582470e-02  1.85293220e-02 -4.97515313e-02\n  7.08907843e-02 -3.29835992e-03 -2.87124477e-02 -2.54332684e-02\n  1.53995762e-02 -1.97981186e-02  1.90643650e-02 -1.43577494e-02\n  7.55839497e-02  7.12002218e-02  2.91497260e-03  2.77490672e-02\n -2.43456122e-02  2.84975283e-02  4.33057267e-03 -4.78617288e-02\n -1.11867127e-03 -1.30365696e-02  3.99887152e-02 -3.94737497e-02\n -5.87339047e-03 -2.73625329e-02 -3.73330116e-02  3.18503997e-04\n  3.17486119e-03  5.19504882e-02 -4.55030277e-02  4.11404967e-02\n  2.30738427e-02 -2.46647839e-02  9.64821223e-03 -3.35802957e-02\n -2.78133736e-03  1.21895615e-02  6.72177505e-03 -9.74690821e-03\n -1.79658495e-02  5.68567659e-04  7.04712840e-03 -3.13434936e-02\n -1.41007295e-02 -3.62862572e-02 -2.98834536e-02 -8.61929730e-03\n  8.38584825e-03  4.45394143e-02 -3.35683078e-02 -1.31782368e-02\n -3.75523022e-03 -3.16639729e-02 -5.17513156e-02 -3.71569023e-02\n  7.64242373e-03  1.25745833e-01  5.65760443e-03 -3.87276635e-02\n -1.19202712e-04  6.27947226e-02  2.50384361e-02  3.44394185e-02\n  1.18035423e-02 -2.74101608e-02  4.66977209e-02 -4.46320686e-04\n -2.36276910e-03 -4.78680730e-02  6.96524512e-04 -2.57363562e-02\n  3.26252513e-04 -4.47232984e-02 -2.21615303e-02  1.10112950e-02\n -1.49798649e-03  1.55940205e-02  1.77136716e-02 -3.31055485e-02\n -1.96988080e-02  5.81257604e-03 -9.16397106e-03 -4.70293239e-02\n -3.93853746e-02  8.84819124e-03  1.15703242e-02  3.93209234e-03\n  3.72772501e-03 -1.80939715e-02  7.24904612e-02  2.29876488e-02\n  1.43688079e-02 -1.01736477e-02 -7.79949967e-03 -1.90648134e-03\n  1.20839579e-02 -1.13552902e-02 -2.89853755e-02  4.12103516e-04\n  4.70356382e-02  7.99963400e-02 -1.10310540e-02  1.01776654e-02\n  9.58971586e-03  5.16173840e-02  2.66598575e-02 -6.72822297e-02\n  3.09747681e-02 -2.82663126e-02  3.87661979e-02  5.11990581e-03\n -1.59728024e-02 -5.70112132e-02 -2.61767884e-03 -3.98402661e-03\n -1.18022915e-02 -2.53608800e-03  1.22967632e-02  4.89425063e-02\n -4.23012505e-04  3.49215753e-02  3.16790454e-02 -5.27992100e-03\n  2.76279394e-02 -4.38188687e-02 -4.75088656e-02 -2.55370624e-02\n  3.76274250e-02 -2.63154972e-02 -1.89469233e-02 -6.74046902e-03\n -1.35034195e-03 -6.52198121e-02  8.39979108e-03 -1.62736177e-02\n  3.49826850e-02 -4.31799032e-02  1.89671777e-02 -1.77272558e-02\n -5.10789230e-02  3.87125090e-02 -3.85339707e-02  5.68695599e-03\n -3.38745723e-03 -4.37672287e-02  5.14479168e-02 -3.68278027e-02\n  1.62972398e-02  2.32295673e-02  3.56925987e-02 -2.67856251e-02\n -1.65193770e-02 -3.13398847e-03 -2.65776385e-02 -7.93772191e-03\n -1.77925434e-02 -6.11093827e-02 -1.47004169e-03 -1.50916204e-02\n  2.49094255e-02  4.33518784e-03  1.06231943e-02  4.43444587e-02\n -7.62529224e-02 -3.08764428e-02 -3.73066142e-02  4.93864305e-02\n  3.98838222e-02 -8.61893687e-03 -3.29699814e-02  7.85417855e-03\n  6.85432507e-03 -1.71071757e-02  4.18841690e-02 -7.64539391e-02\n  4.33914252e-02  8.79432037e-02  4.75995429e-02 -4.11684550e-02\n -1.09945647e-02  2.09075715e-02 -9.77121294e-02 -6.45583123e-03\n  1.63567420e-02 -2.51106378e-02  3.48496176e-02 -6.63355645e-03\n -1.98882334e-02  2.15651700e-03 -7.01613724e-02 -3.54075842e-02\n  2.60366164e-02  1.00997146e-02  2.49071792e-02 -5.28508518e-03\n -2.52017789e-02 -2.96847839e-02  2.70613823e-02  1.64177660e-02\n -3.10335848e-02 -1.18135720e-01  4.26516077e-03  2.44129412e-02\n  5.51338028e-03  3.43936384e-02 -6.79047080e-05  4.31150496e-02\n -7.01375818e-03 -5.16205281e-03  2.45724395e-02 -1.21860765e-01\n  4.63019498e-02  8.55250582e-02 -3.33464448e-03 -5.57449721e-02\n -1.09275170e-02  1.73359644e-02 -1.91021003e-02 -2.87620630e-02\n -4.85176966e-03  2.42441148e-02  6.03003725e-02  7.34636374e-03\n -6.58913329e-02 -2.17981040e-02  4.02666144e-02  2.50547007e-03\n  2.70507429e-02  1.71557423e-02  1.69114247e-02  1.55144110e-02\n  2.24949438e-02  1.09874420e-02  1.88002046e-02  4.53582965e-03\n  1.79268373e-03  6.99624093e-03 -4.80596647e-02  3.08817774e-02\n  1.36245275e-02 -3.20214778e-02 -4.05726694e-02 -4.72657979e-02\n  2.96804346e-02 -5.52344956e-02  5.94026595e-03  2.85609043e-04\n -1.22749843e-02 -1.23383822e-02 -9.27929673e-03 -9.63241700e-03\n  1.30024459e-02  7.94234052e-02 -1.35290939e-02 -4.00234535e-02\n  1.24088004e-02 -3.00377365e-02  4.62444276e-02 -2.15973763e-04\n -1.60418767e-02 -2.88399849e-02  2.04387736e-02 -6.75940374e-03\n -1.50114838e-02 -7.63812568e-03 -1.75065994e-02 -8.69040787e-02\n -7.46335238e-02  1.63677670e-02  6.80913043e-04  5.05806543e-02\n -2.56011970e-02 -3.79000306e-02 -7.58246258e-02  1.03536071e-02\n -5.44604994e-02 -7.47085586e-02  1.41446544e-02  1.66898891e-02\n  1.02182794e-02  8.68633017e-03 -3.56266238e-02  1.26684457e-02\n -5.40778413e-02  6.87354133e-02 -7.79730007e-02  2.60117278e-03\n -4.27175220e-03  1.09971752e-02  8.92479531e-03  9.24521126e-04\n  1.29508565e-03 -1.73942912e-02 -1.30676609e-02 -3.52515676e-03\n -2.56819651e-02  1.01649761e-02 -9.04367026e-03  3.98797961e-03\n -4.65250090e-02  2.84145325e-02  3.74951004e-03  2.65063886e-02\n  2.21090503e-02  3.65748629e-02 -3.23049016e-02  3.35518597e-03\n  1.74077172e-02  3.69972992e-03 -7.29519175e-03  1.76396146e-02\n  2.71766260e-02  5.31552583e-02  2.82585938e-02  1.83973126e-02\n -6.16295226e-02 -4.21744287e-02  9.34302434e-02 -5.66754304e-02\n -8.13768897e-03  1.20670879e-02 -1.97449364e-02 -1.17568029e-02\n -1.11968825e-02 -3.05508953e-02  1.13354316e-02 -1.08850673e-02\n -1.66359562e-02 -2.29499186e-03  3.59796616e-03 -1.24789113e-02\n -2.20422409e-02 -3.37510109e-02  4.77207340e-02 -1.73705351e-02\n  3.50818038e-02 -8.80621467e-03  2.84616519e-02  2.71866564e-02\n -1.96970031e-02  1.65863372e-02  1.19530444e-03 -2.92669181e-02\n  1.72919277e-02 -3.13186981e-02  6.01529656e-03  2.25897748e-02\n  1.74147226e-02 -4.12616320e-02  5.85532188e-03  5.35180680e-02\n  5.58125898e-02  4.00458276e-02  1.16849868e-02  2.41086837e-02\n -4.78722388e-03  6.64723441e-02 -1.01832021e-03 -5.69077581e-02\n  2.13917177e-02  8.82170163e-03  6.24029078e-02  3.60345878e-02\n -4.93079014e-02  3.41875777e-02 -8.86109378e-03  1.29644796e-02\n  4.90984730e-02 -2.05017123e-02 -2.73573841e-03 -7.69184530e-02\n -5.38677387e-02 -5.16973510e-02  5.85781783e-02 -6.15020885e-33\n  1.16113657e-02 -1.16522266e-02 -3.68662900e-03 -1.74251944e-03\n -5.05884662e-02  8.76333285e-03  3.56312562e-03  6.98931189e-03\n -6.41284930e-03 -1.86328758e-02  3.21220830e-02  1.24927703e-02\n -4.23061568e-03  3.09763476e-02 -1.51065318e-02  3.31984386e-02\n  2.90168673e-02  5.64335845e-02 -3.94090032e-03 -1.67538393e-02\n -1.60394367e-02  6.56500086e-03  7.80047663e-03 -5.53862937e-02\n  2.41907407e-02 -1.43446755e-02  7.50727253e-03 -4.65504033e-03\n  3.25727686e-02  2.62190010e-02  8.46764352e-03 -5.15125692e-02\n  9.45906062e-03 -1.18356952e-02  1.28131136e-02 -1.72146782e-02\n -4.93238345e-02  1.00119617e-02  8.62771831e-03  4.26262096e-02\n -3.32272314e-02 -9.69304815e-02  6.95233792e-03 -1.27162915e-02\n  2.75861993e-02 -9.20861773e-03 -6.91513065e-03 -1.66155826e-02\n  1.17112892e-02 -9.74554345e-02 -5.21131903e-02 -9.47220717e-03\n  3.43528576e-03  2.41525546e-02  1.26525545e-02  4.03679535e-02\n -2.65859012e-02 -5.17518669e-02  5.76242618e-02  2.99946070e-02\n -2.00340375e-02 -3.26884687e-02 -1.69149954e-02 -2.97283176e-02\n  1.67640075e-02 -1.28456317e-02 -1.58242732e-02 -2.66360641e-02\n -5.21737263e-02  5.08641936e-02  1.45849222e-02  1.24559936e-03\n  2.71272510e-02  9.66960266e-02  1.28149716e-02 -7.09765358e-03\n -3.47179249e-02  2.49626171e-02  9.30798799e-03 -6.89559523e-03\n  5.71426079e-02  1.92884952e-02 -7.53424615e-02  4.01675440e-02\n -3.81068303e-03  7.99634978e-02 -1.42071126e-02 -2.37909760e-02\n  3.46525386e-02 -1.49838049e-02 -5.93865998e-02 -1.01487676e-03\n -5.21531254e-02 -4.39878404e-02  6.97664022e-02  4.12533320e-02\n  3.63477468e-02 -5.34341447e-02  2.73667816e-02 -1.54123651e-02\n  1.28830358e-01  7.66366394e-03  6.94627780e-03 -2.11688075e-02\n  2.91196839e-03  7.15040741e-03 -4.08192500e-02  3.41010317e-02\n -5.19427657e-03  9.10451636e-03  2.13447455e-02 -1.83989375e-03\n -1.51564851e-02 -2.17404850e-02  7.68181449e-03 -6.85032234e-02\n  8.14647134e-03 -2.62931120e-02  1.55845918e-02  3.05560641e-02\n  5.28977811e-02  7.82851651e-02 -3.93773010e-03  3.07237674e-02\n  2.89140977e-02  2.19724625e-02 -1.06112398e-02  3.69371325e-02\n -7.06979036e-02 -3.79267968e-02 -5.31094931e-02  3.52745205e-02\n  2.81861560e-07 -1.52249318e-02  6.03180937e-02  7.06116110e-03\n  4.16149497e-02 -9.37373901e-04 -4.28261347e-02  4.59849685e-02\n  1.54953236e-02 -4.57429178e-02  1.29765896e-02  5.25619602e-03\n  4.11267579e-02 -2.49698292e-02  2.63094231e-02 -8.85944907e-03\n -8.62354562e-02  2.87570357e-02 -7.12938327e-03 -3.27352025e-02\n -2.63189338e-02  1.20814390e-01  3.18851471e-02 -2.03403030e-02\n -3.10703199e-02 -1.14337625e-02  1.90644227e-02 -5.87653648e-03\n -8.22500233e-03  2.19477508e-02 -1.59391724e-02 -2.16257526e-03\n  2.61115339e-02 -2.44061667e-02 -8.69395137e-02  3.89402770e-02\n -6.22375831e-02  5.04101887e-02  3.79639193e-02 -1.26464653e-03\n -5.33055551e-02  9.57892183e-03  2.43446138e-02 -4.06210357e-03\n -6.61535338e-02  2.10537221e-02  1.14850119e-01 -9.05924942e-03\n -1.07338741e-01 -5.24651557e-02  1.36263892e-02  2.65873279e-02\n -1.45666003e-02 -1.30288638e-02 -1.77523028e-02 -6.60713995e-03\n -2.56726220e-02  1.16631866e-03 -1.02037340e-02  1.63282137e-02\n  1.04058862e-01  9.50932782e-03  1.87795404e-02  4.30704793e-03\n -1.73487943e-02 -9.20979492e-03 -7.24763945e-02 -1.88865175e-03\n  2.22371733e-34  2.46033650e-02  1.06864306e-03  5.14988936e-02\n -2.97110230e-02  2.07253955e-02  1.32365441e-02 -2.92844046e-02\n -4.47769416e-03  2.19273730e-03  8.43835715e-03 -7.55130954e-04].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "sim_1_2 = weighted_similarity(g_1[['desc_embeddings', 'genre_embeddings']].values[0], g_2[['desc_embeddings', 'genre_embeddings']].values[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-25T18:01:24.152314Z",
     "start_time": "2024-10-25T18:01:23.966956Z"
    }
   },
   "id": "f328e8632c716fc0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "fe6d46553b586d9b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
